## Web Archiving Overview

Seeders canvass the resources of a given government agency, identifying important URLs. They identify whether those URLs can be crawled by the Internet Archive's webcrawler. If the URLs are crawlable, the seeders nominate them to the End-of-Term (EOT) project; otherwise they add them to the queue for harvesting by the data archivers.

## Choosing the website
The web archiving team will use the [EDGI subprimers](https://envirodatagov.org/agency-forecasts/) to identify important/at-risk data. Talk to a web archiving guide to learn more.

## Canvassing the website and evaluating content
- Start exploring the website assigned, identifying important URLs. 
- Decide whether the data on a page or website subsection can be [automatically captured by the Internet Archive webcrawler](https://docs.google.com/document/d/1PeWefW2toThs-Pbw0CMv2us7wxQI0gRrP1LGuwMp_UQ/edit).
- See also [Seeding the IA's webcrawler](https://docs.google.com/document/d/1qpuNCmBmu4KcsS_hE2srewcCiP4f9P5cCyDfHmsSAVU/edit) and documentation at [https://envirodatagov.org/](https://envirodatagov.org/).
 
## Using the Nomination Tool Chrome Extension

The [EDGI Nomination Chrome extension](https://chrome.google.com/webstore/detail/nominationtool/abjpihafglmijnkkoppbookfkkanklok?hl=en) is a simple tool for identifying important URLs and moving them into the Data Rescue system. Resources that can be captured by the Internet Archive will be "nominated" to the IA crawl. Resources that cannot be captured by the IA will be added to the queue for harvesting by data archivers. There is some overlap between these two categories, so some resource will be **both** nominated and data archived. 
